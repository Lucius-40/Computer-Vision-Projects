{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN8aN4vyGMXd8ynjNI176D9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Lucius-40/Computer-Vision-Projects/blob/main/CIFAR-10/Object_recognition_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook , i will try a deeper CNN with more units and try a disk saving augmentation approach and dropout and learning rate scheduling to hopefully see improvements in accuracy from the previous notebook"
      ],
      "metadata": {
        "id": "OsUFvyf7ieqJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZVZEefPwidCW",
        "outputId": "4a8487a1-b542-4a23-8f5f-3a39b050e0ad"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch.optim as optim\n",
        "from PIL import Image\n",
        "import os\n",
        "import random\n",
        "from torchvision.datasets import ImageFolder\n",
        "\n",
        "\n",
        "\n",
        "# Check GPU availability\n",
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Output directory for augmented dataset\n",
        "OUTPUT_DIR = './augmented_cifar10'\n",
        "NUM_AUG_PER_IMAGE = 4\n",
        "IMAGE_SIZE = 32\n",
        "\n",
        "# CIFAR-10 normalization stats\n",
        "mean = (0.4914, 0.4822, 0.4465)\n",
        "std = (0.2470, 0.2435, 0.2616)\n",
        "\n",
        "# Base spatial transforms\n",
        "base_transform = transforms.Compose([\n",
        "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip()\n",
        "])\n",
        "\n",
        "# Extra augmentation pool\n",
        "augmentation_pool = [\n",
        "    transforms.RandomRotation(20),\n",
        "    transforms.ColorJitter(brightness=0.01, contrast=0.01, saturation=0.01),\n",
        "    transforms.RandomAdjustSharpness(sharpness_factor=2, p=1.0),  # always apply\n",
        "    transforms.RandomInvert(p=1.0)\n",
        "]\n",
        "\n",
        "# Load CIFAR-10 training set (no transform yet)\n",
        "dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True)\n",
        "\n",
        "# Create class-name folders\n",
        "for class_name in dataset.classes:  # ['airplane', 'automobile', ...]\n",
        "    os.makedirs(os.path.join(OUTPUT_DIR, class_name), exist_ok=True)\n",
        "\n",
        "# Loop through dataset and save augmented images\n",
        "for idx, (image, label) in enumerate(dataset):\n",
        "    class_name = dataset.classes[label]\n",
        "    class_dir = os.path.join(OUTPUT_DIR, class_name)\n",
        "\n",
        "    # Save original image\n",
        "    image.save(os.path.join(class_dir, f\"{idx:05d}_orig.png\"))\n",
        "\n",
        "    # Generate multiple augmented versions\n",
        "    for aug_idx in range(NUM_AUG_PER_IMAGE):\n",
        "        img_aug = base_transform(image)  # spatial aug first\n",
        "        aug = random.choice(augmentation_pool)  # pick one extra aug\n",
        "        img_aug = aug(img_aug)\n",
        "        img_aug.save(os.path.join(class_dir, f\"{idx:05d}_aug{aug_idx}.png\"))\n",
        "\n",
        "    if idx % 5000 == 0:\n",
        "        print(f\"Processed {idx} images...\")\n",
        "\n",
        "print(\"Augmentation complete! Images saved in class-name folders.\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c_pR7tMCjAqW",
        "outputId": "c9293edc-e1ee-4c69-9e00-848199bf22d5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:03<00:00, 47.9MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 0 images...\n",
            "Processed 5000 images...\n",
            "Processed 10000 images...\n",
            "Processed 15000 images...\n",
            "Processed 20000 images...\n",
            "Processed 25000 images...\n",
            "Processed 30000 images...\n",
            "Processed 35000 images...\n",
            "Processed 40000 images...\n",
            "Processed 45000 images...\n",
            "Augmentation complete! Images saved in class-name folders.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform_train = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean, std)\n",
        "])\n",
        "\n",
        "\n",
        "train_dataset = ImageFolder(root=OUTPUT_DIR, transform=transform_train)\n",
        "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=2)\n",
        "\n",
        "print(f\"Total images: {len(train_dataset)}\")\n",
        "print(f\"Classes: {train_dataset.classes}\")  # Matches CIFAR-10 exactly\n",
        "\n",
        "\n",
        "test_dataset = torchvision.datasets.CIFAR10(\n",
        "    root='./data', train=False, download=True, transform=transform_train\n",
        ")\n",
        "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "print(f\"Test classes: {test_dataset.classes}\")  # Same order as train_dataset.classes\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VMPdqRmJl3x8",
        "outputId": "ec0435e4-d6b9-4b02-f96f-7852e28b0501"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total images: 250000\n",
            "Classes: ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
            "Test classes: ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"total Images \", len(test_dataset))\n",
        "print(test_dataset.classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A2RluLoKmKcc",
        "outputId": "a3108285-aa7b-480d-8074-ba962ce55dd1"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total Images  10000\n",
            "['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**New Model **"
      ],
      "metadata": {
        "id": "-jSQZrG3qAhH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN,self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.batchnorm1 = nn.BatchNorm2d(32)\n",
        "\n",
        "\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.batchnorm2 = nn.BatchNorm2d(64)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride = 1, padding=1)\n",
        "        self.batchnorm3 = nn.BatchNorm2d(128)\n",
        "\n",
        "        self.dense1 = nn.Linear(4 * 4* 128, 150)\n",
        "        self.batchnorm4 = nn.BatchNorm1d(150)\n",
        "\n",
        "        self.dense2 = nn.Linear(150, 120 )\n",
        "        self.batchnorm5 = nn.BatchNorm1d(120)\n",
        "\n",
        "        self.output = nn.Linear(120,10)\n",
        "\n",
        "        self.pool = nn.MaxPool2d(2,2)\n",
        "        self.conv_drop = nn.Dropout2d(p=0.1)\n",
        "        self.dense_drop = nn.Dropout(p=0.2)\n",
        "\n",
        "    def forward(self, X):\n",
        "        X = self.pool(torch.relu(self.batchnorm1(self.conv1(X))))\n",
        "        X= self.conv_drop(X)\n",
        "\n",
        "        X = self.pool(torch.relu(self.batchnorm2(self.conv2(X))))\n",
        "        X=self.conv_drop(X)\n",
        "\n",
        "        X = self.pool(torch.relu(self.batchnorm3(self.conv3(X))))\n",
        "        X=self.conv_drop(X)\n",
        "\n",
        "        X = X.view(X.size(0),-1 )\n",
        "        X = torch.relu(self.batchnorm4(self.dense1(X)))\n",
        "        X=self.dense_drop(X)\n",
        "\n",
        "        X = torch.relu(self.batchnorm5(self.dense2(X)))\n",
        "        X=self.dense_drop(X)\n",
        "\n",
        "        X = self.output(X)\n",
        "        return X"
      ],
      "metadata": {
        "id": "oJnlFz3Dp9ur"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = CNN()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(\n",
        "    model.parameters(),\n",
        "    lr=0.1,\n",
        "    momentum=0.6,\n",
        "    weight_decay=1e-4\n",
        ")\n",
        "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=70, eta_min=1e-5)\n"
      ],
      "metadata": {
        "id": "JAwiOTFdy5hH"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The training loop :"
      ],
      "metadata": {
        "id": "p6QTVMMH9Cc-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "for epoch in range(70):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for images, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "    epoch_loss = running_loss / len(train_loader)\n",
        "    epoch_acc = 100 * correct / total\n",
        "    print(f\"Epoch {epoch+1}, Loss: {epoch_loss:.4f}, Acc: {epoch_acc:.2f}%\")\n",
        "    '''\n",
        "for epoch in range(70):\n",
        "    # ---- TRAIN ----\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for images, labels in train_loader:\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    train_loss = running_loss / len(train_loader)\n",
        "    train_acc = 100 * correct / total\n",
        "\n",
        "    model.eval()\n",
        "    test_loss = 0.0\n",
        "    correct_test = 0\n",
        "    total_test = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            test_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total_test += labels.size(0)\n",
        "            correct_test += (predicted == labels).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader)\n",
        "    test_acc = 100 * correct_test / total_test\n",
        "\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/70] \"\n",
        "          f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}% \"\n",
        "          f\"Test Loss: {test_loss:.4f} | Test Acc: {test_acc:.2f}%\")\n",
        "\n"
      ],
      "metadata": {
        "id": "tC408NWZ9E3d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "r0n2EklEy7aN"
      },
      "execution_count": 6,
      "outputs": []
    }
  ]
}